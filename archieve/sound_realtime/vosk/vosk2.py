import os
import time
import queue
import threading
import wave
import numpy as np
import pyaudio
from vosk import Model, KaldiRecognizer

# è¼‰å…¥ Vosk æ¨¡å‹ï¼ˆè‡ªå‹•æŒ‡å®šï¼‰
MODEL_PATH = "C:/Users/Key20/Desktop/vosk-model-small-cn-0.22"
model = Model(MODEL_PATH)

# éŸ³è¨Šåƒæ•¸
RATE = 16000
CHANNELS = 1
CHUNK = 1024
SILENCE_THRESHOLD = 300  # éŸ³é‡å°æ–¼æ­¤è¦–ç‚ºéœéŸ³
MAX_SILENCE_CHUNKS = 10  # åœé “å¤šå°‘å€‹ chunk ç®—ä½œä¸€å¥è©±çµæŸ

# ä½‡åˆ—ï¼šå„²å­˜éŸ³è¨Šç‰‡æ®µ
audio_queue = queue.Queue()

# Recorder åŸ·è¡Œç·’ï¼ˆProducerï¼‰
def audio_producer():
    pa = pyaudio.PyAudio()
    stream = pa.open(format=pyaudio.paInt16,
                     channels=CHANNELS,
                     rate=RATE,
                     input=True,
                     frames_per_buffer=CHUNK)
    print("ğŸ¤ éŒ„éŸ³é–‹å§‹ï¼Œè«‹èªªè©±...")

    frames = []
    silence_count = 0
    voice_frame_count = 0
    start_time = time.time()

    while True:
        data = stream.read(CHUNK)
        audio = np.frombuffer(data, dtype=np.int16)
        volume = np.abs(audio).mean()

        frames.append(data)

        if volume < SILENCE_THRESHOLD:
            silence_count += 1
        else:
            silence_count = 0
            voice_frame_count += 1

        if silence_count > MAX_SILENCE_CHUNKS:
            if voice_frame_count > 3:  # æœ‰å¯¦éš›è¬›è©±æ‰é€å‡º
                timestamp = time.strftime("%H:%M:%S", time.localtime(start_time))
                audio_queue.put((b''.join(frames), timestamp))
                print(f"\nâ± æ®µè½åµæ¸¬ï¼ˆæœ‰è¬›è©±ï¼‰ âœ {timestamp}")
            #else:
                #print(f"\nğŸ’¤ æ®µè½ç‚ºéœéŸ³ï¼Œç•¥é")

            # é‡ç½®
            frames = []
            start_time = time.time()
            silence_count = 0
            voice_frame_count = 0

# Consumer è™•ç†èªéŸ³ï¼ˆå¯é–‹å¤šåŸ·è¡Œç·’ï¼‰
def audio_consumer(worker_id):
    while True:
        audio_data, timestamp = audio_queue.get()
        recognizer = KaldiRecognizer(model, RATE)
        recognizer.AcceptWaveform(audio_data)
        result = recognizer.Result()
        import json
        text = json.loads(result).get("text", "")
        if text.strip():
            print(f"\nğŸ§  [{timestamp}] Worker-{worker_id} è¾¨è­˜çµæœï¼š\n{text}\n")
        else:
            print(f"\nâ“ [{timestamp}] Worker-{worker_id} ç„¡æ³•è¾¨è­˜å…§å®¹ã€‚")

# å•Ÿå‹•ç³»çµ±
if __name__ == "__main__":
    # å•Ÿå‹•éŒ„éŸ³åŸ·è¡Œç·’
    threading.Thread(target=audio_producer, daemon=True).start()

    # å•Ÿå‹•å¤šå€‹èªéŸ³è¾¨è­˜ Worker åŸ·è¡Œç·’
    for i in range(2):  # å¯ä»¥ä¾ç¡¬é«”èƒ½åŠ›èª¿æ•´ worker æ•¸é‡
        threading.Thread(target=audio_consumer, args=(i+1,), daemon=True).start()

    while True:
        time.sleep(1)
